@book{arenales2007pesquisa,
  address = {Rio de Janeiro, RJ},
  author = {Arenales, Marcos and Vinícius and Reinaldo and Horacio and Armêniano and Morabito and Yanasse},
  edition = {1},
  isbn = {9788535251937},
  organization = {Associação Brasileira de Engenharia de Produção},
  publisher = {Elsevier : ABEPRO},
  series = {COLEÇÃO CAMPUS - ABEPRO Engenharia de Produção},
  title = {Pesquisa Operacional},
  url = {www.campus.com.br},
  year = {2007}
@book{arenales2007pesquisa,
  address = {Rio de Janeiro, RJ},
  author = {Arenales, Marcos and Vinícius and Reinaldo and Horacio and Armêniano and Morabito and Yanasse},
  edition = {1},
  isbn = {9788535251937},
  organization = {Associação Brasileira de Engenharia de Produção},
  publisher = {Elsevier : ABEPRO},
  series = {COLEÇÃO CAMPUS - ABEPRO Engenharia de Produção},
  title = {Pesquisa Operacional},
  url = {www.campus.com.br},
  year = {2007}
}
@book{goldbarg2005otimizacao,
  title = {Otimização combinatória e programação linear: modelos e algoritmos},
  author = {Goldbarg, Marco Cesar and Luna, Henrique Pacca L.},
  edition = {2},
  year = {2005},
  address = {Rio de Janeiro},
  publisher = {Elsevier},
  isbn = {978-85-352-1520-5}
}
@article{yilmaz2021modeling,
  author = {Yilmaz, H.},
  title = {Modeling and solving assembly line worker assignment and balancing problem with sequence-dependent setup times},
  journal = {Soft Computing},
  volume = {25},
  pages = {12899--12914},
  year = {2021},
  doi = {10.1007/s00500-021-06107-3},
  issn = {1432-7643},
  url = {https://doi.org/10.1007/s00500-021-06107-3}
}
@Book{ Luke2013Metaheuristics, 
       author =    { Sean Luke }, 
       title =     { Essentials of Metaheuristics },
       edition =   { second },
       year =      { 2013 }, 
       publisher = { Lulu },
       note =      { Available for free at http://cs.gmu.edu/$\sim$sean/book/metaheuristics/ } 
     }
@article{glover2015metaheuristics,
  author = {Glover, Fred and S{\"o}rensen, Kenneth},
  title = {Metaheuristics},
  journal = {Scholarpedia},
  volume = {10},
  number = {4},
  pages = {6532},
  year = {2015},
  doi = {10.4249/scholarpedia.6532},
  url = {http://dx.doi.org/10.4249/scholarpedia.6532}
}
@incollection{sorensen2013metaheuristics,
  author = {S{\"o}rensen, K. and Glover, F.},
  title = {Metaheuristics},
  booktitle = {Encyclopedia of Operations Research and Management Science},
  editor = {Gass, S.I. and Fu, M.},
  publisher = {Springer},
  address = {New York},
  year = {2013}
}
@article{lourenco2001gentle,
  title = {A Gentle Introduction to Iterated Local Search},
  author = {Louren{\c{c}}o, Helena Ramalhinho and Martin, Olivier and St{\"u}tzle, Thomas},
  year = {2001},
  journal = {Proceedings of MIC 2001 - 4th Metaheuristics International Conference},
  volume = {1},
  pages = {1--6},
  publisher = {MIC},
  url = {https://www.metaheuristics.org/downloads/mic2001-ils.pdf},
  urldate = {2025-01-10}
}
@article{helgeson1961assembly,
  title={Assembly line balancing using the ranked positional weight technique},
  author={Helgeson, WB and Birnie, Dunbar P},
  journal={Journal of industrial engineering},
  volume={12},
  number={6},
  pages={394--398},
  year={1961}
}
@article{HANSEN2001449,
title = {Variable neighborhood search: Principles and applications},
journal = {European Journal of Operational Research},
volume = {130},
number = {3},
pages = {449-467},
year = {2001},
issn = {0377-2217},
doi = {https://doi.org/10.1016/S0377-2217(00)00100-4},
url = {https://www.sciencedirect.com/science/article/pii/S0377221700001004},
author = {Pierre Hansen and Nenad Mladenović},
keywords = {Heuristic, Metaheuristic, Variable neighborhood search, VNS},
abstract = {Systematic change of neighborhood within a possibly randomized local search algorithm yields a simple and effective metaheuristic for combinatorial and global optimization, called variable neighborhood search (VNS). We present a basic scheme for this purpose, which can easily be implemented using any local search algorithm as a subroutine. Its effectiveness is illustrated by solving several classical combinatorial or global optimization problems. Moreover, several extensions are proposed for solving large problem instances: using VNS within the successive approximation method yields a two-level VNS, called variable neighborhood decomposition search (VNDS); modifying the basic scheme to explore easily valleys far from the incumbent solution yields an efficient skewed VNS (SVNS) heuristic. Finally, we show how to stabilize column generation algorithms with help of VNS and discuss various ways to use VNS in graph theory, i.e., to suggest, disprove or give hints on how to prove conjectures, an area where metaheuristics do not appear to have been applied before.}
}
@article{Polat01022016,
author = {Olcay Polat and Can B. Kalayci and Özcan Mutlu and Surendra M. Gupta},
title = {A two-phase variable neighbourhood search algorithm for assembly line worker assignment and balancing problem type-II: an industrial case study},
journal = {International Journal of Production Research},
volume = {54},
number = {3},
pages = {722--741},
year = {2016},
publisher = {Taylor \& Francis},
doi = {10.1080/00207543.2015.1055344},
URL = { 
        https://doi.org/10.1080/00207543.2015.1055344
},
eprint = { 
    
        https://doi.org/10.1080/00207543.2015.1055344
}
}
@article{kirkpatrick1983,
author = {S. Kirkpatrick  and C. D. Gelatt  and M. P. Vecchi },
title = {Optimization by Simulated Annealing},
journal = {Science},
volume = {220},
number = {4598},
pages = {671-680},
year = {1983},
doi = {10.1126/science.220.4598.671},
URL = {https://www.science.org/doi/abs/10.1126/science.220.4598.671},
eprint = {https://www.science.org/doi/pdf/10.1126/science.220.4598.671},
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.}
}
@Inbook{vanLaarhoven1987,
author="van Laarhoven, Peter J. M.
and Aarts, Emile H. L.",
title="Simulated annealing",
bookTitle="Simulated Annealing: Theory and Applications",
year="1987",
publisher="Springer Netherlands",
address="Dordrecht",
pages="7--15",
abstract="In its original form [KIR82], [{\v{C}}ER85] the simulated annealing algorithm is based on the analogy between the simulation of the annealing pf solids and the problem of solving large combinatorial optimization problems. For this reason the algorithm became known as ``simulated annealing''. In condensed matter physics, annealing denotes a physical process in which a solid in a heat bath is heated up by increasing the temperature of the heat bath to a maximum value at which all particles of the solid randomly arrange themselves in the liquid phase, followed by cooling through slowly lowering the temperature of the heat bath. In this way, all particles arrange themselves in the low energy ground state of a corresponding lattice, provided the maximum temperature is sufficiently high and the cooling is carried out sufficiently slowly. Starting off at the maximum value of the temperature, the cooling phase of the annealing process can be described as follows.",
isbn="978-94-015-7744-1",
doi="10.1007/978-94-015-7744-1_2",
url="https://doi.org/10.1007/978-94-015-7744-1_2"
}
@inproceedings{akiba2019optuna,
author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
title = {Optuna: A Next-generation Hyperparameter Optimization Framework},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330701},
doi = {10.1145/3292500.3330701},
abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2623–2631},
numpages = {9},
keywords = {Bayesian optimization, black-box optimization, hyperparameter optimization, machine learning system},
location = {Anchorage, AK, USA},
series = {KDD '19}
}